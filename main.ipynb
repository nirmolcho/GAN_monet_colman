{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (2.2.0)\r\n",
      "Requirement already satisfied: numpy in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (1.24.4)\r\n",
      "Requirement already satisfied: tensorflow in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (2.15.0)\r\n",
      "Requirement already satisfied: keras in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (2.15.0)\r\n",
      "Requirement already satisfied: torch in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (2.1.2)\r\n",
      "Collecting scikit-learn (from -r requirements.txt (line 6))\r\n",
      "  Downloading scikit_learn-1.4.0-1-cp311-cp311-macosx_12_0_arm64.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: matplotlib in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (3.8.2)\r\n",
      "Collecting seaborn (from -r requirements.txt (line 8))\r\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\r\n",
      "Collecting scipy (from -r requirements.txt (line 9))\r\n",
      "  Downloading scipy-1.12.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (165 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m165.4/165.4 kB\u001B[0m \u001B[31m961.4 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: jupyter in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (1.0.0)\r\n",
      "Collecting opencv-python (from -r requirements.txt (line 11))\r\n",
      "  Downloading opencv_python-4.9.0.80-cp37-abi3-macosx_11_0_arm64.whl.metadata (20 kB)\r\n",
      "Requirement already satisfied: tqdm in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (4.66.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 1)) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 1)) (2023.4)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 1)) (2023.4)\r\n",
      "Requirement already satisfied: tensorflow-macos==2.15.0 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 3)) (2.15.0)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 3)) (2.1.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 3)) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 3)) (23.5.26)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 3)) (0.5.4)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 3)) (0.2.0)\r\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 3)) (3.10.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 3)) (16.0.6)\r\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 3)) (0.2.0)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 3)) (3.3.0)\r\n",
      "Requirement already satisfied: packaging in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 3)) (23.2)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 3)) (4.23.4)\r\n",
      "Requirement already satisfied: setuptools in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 3)) (68.2.2)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 3)) (1.16.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 3)) (2.4.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 3)) (4.9.0)\r\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 3)) (1.14.1)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 3)) (0.36.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 3)) (1.60.1)\r\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 3)) (2.15.1)\r\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 3)) (2.15.0)\r\n",
      "Requirement already satisfied: filelock in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from torch->-r requirements.txt (line 5)) (3.13.1)\r\n",
      "Requirement already satisfied: sympy in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from torch->-r requirements.txt (line 5)) (1.12)\r\n",
      "Requirement already satisfied: networkx in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from torch->-r requirements.txt (line 5)) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from torch->-r requirements.txt (line 5)) (3.1.3)\r\n",
      "Requirement already satisfied: fsspec in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from torch->-r requirements.txt (line 5)) (2023.12.2)\r\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->-r requirements.txt (line 6))\r\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\r\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn->-r requirements.txt (line 6))\r\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 7)) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 7)) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 7)) (4.48.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 7)) (1.4.5)\r\n",
      "Requirement already satisfied: pillow>=8 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 7)) (10.2.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 7)) (3.1.1)\r\n",
      "Requirement already satisfied: notebook in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from jupyter->-r requirements.txt (line 10)) (7.0.7)\r\n",
      "Requirement already satisfied: qtconsole in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from jupyter->-r requirements.txt (line 10)) (5.5.1)\r\n",
      "Requirement already satisfied: jupyter-console in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from jupyter->-r requirements.txt (line 10)) (6.6.3)\r\n",
      "Requirement already satisfied: nbconvert in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from jupyter->-r requirements.txt (line 10)) (7.14.2)\r\n",
      "Requirement already satisfied: ipykernel in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from jupyter->-r requirements.txt (line 10)) (6.29.0)\r\n",
      "Requirement already satisfied: ipywidgets in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from jupyter->-r requirements.txt (line 10)) (8.1.1)\r\n",
      "Requirement already satisfied: appnope in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from ipykernel->jupyter->-r requirements.txt (line 10)) (0.1.3)\r\n",
      "Requirement already satisfied: comm>=0.1.1 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from ipykernel->jupyter->-r requirements.txt (line 10)) (0.2.1)\r\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from ipykernel->jupyter->-r requirements.txt (line 10)) (1.8.0)\r\n",
      "Requirement already satisfied: ipython>=7.23.1 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from ipykernel->jupyter->-r requirements.txt (line 10)) (8.21.0)\r\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from ipykernel->jupyter->-r requirements.txt (line 10)) (8.6.0)\r\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from ipykernel->jupyter->-r requirements.txt (line 10)) (5.7.1)\r\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from ipykernel->jupyter->-r requirements.txt (line 10)) (0.1.6)\r\n",
      "Requirement already satisfied: nest-asyncio in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from ipykernel->jupyter->-r requirements.txt (line 10)) (1.6.0)\r\n",
      "Requirement already satisfied: psutil in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from ipykernel->jupyter->-r requirements.txt (line 10)) (5.9.8)\r\n",
      "Requirement already satisfied: pyzmq>=24 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from ipykernel->jupyter->-r requirements.txt (line 10)) (25.1.2)\r\n",
      "Requirement already satisfied: tornado>=6.1 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from ipykernel->jupyter->-r requirements.txt (line 10)) (6.4)\r\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from ipykernel->jupyter->-r requirements.txt (line 10)) (5.14.1)\r\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from ipywidgets->jupyter->-r requirements.txt (line 10)) (4.0.9)\r\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from ipywidgets->jupyter->-r requirements.txt (line 10)) (3.0.9)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from jinja2->torch->-r requirements.txt (line 5)) (2.1.4)\r\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from jupyter-console->jupyter->-r requirements.txt (line 10)) (3.0.43)\r\n",
      "Requirement already satisfied: pygments in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from jupyter-console->jupyter->-r requirements.txt (line 10)) (2.17.2)\r\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from nbconvert->jupyter->-r requirements.txt (line 10)) (4.12.3)\r\n",
      "Requirement already satisfied: bleach!=5.0.0 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from nbconvert->jupyter->-r requirements.txt (line 10)) (6.1.0)\r\n",
      "Requirement already satisfied: defusedxml in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from nbconvert->jupyter->-r requirements.txt (line 10)) (0.7.1)\r\n",
      "Requirement already satisfied: jupyterlab-pygments in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from nbconvert->jupyter->-r requirements.txt (line 10)) (0.3.0)\r\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from nbconvert->jupyter->-r requirements.txt (line 10)) (3.0.2)\r\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from nbconvert->jupyter->-r requirements.txt (line 10)) (0.9.0)\r\n",
      "Requirement already satisfied: nbformat>=5.7 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from nbconvert->jupyter->-r requirements.txt (line 10)) (5.9.2)\r\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from nbconvert->jupyter->-r requirements.txt (line 10)) (1.5.1)\r\n",
      "Requirement already satisfied: tinycss2 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from nbconvert->jupyter->-r requirements.txt (line 10)) (1.2.1)\r\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from notebook->jupyter->-r requirements.txt (line 10)) (2.12.5)\r\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.22.1 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from notebook->jupyter->-r requirements.txt (line 10)) (2.25.2)\r\n",
      "Requirement already satisfied: jupyterlab<5,>=4.0.2 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from notebook->jupyter->-r requirements.txt (line 10)) (4.0.12)\r\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from notebook->jupyter->-r requirements.txt (line 10)) (0.2.3)\r\n",
      "Requirement already satisfied: qtpy>=2.4.0 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from qtconsole->jupyter->-r requirements.txt (line 10)) (2.4.1)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from sympy->torch->-r requirements.txt (line 5)) (1.3.0)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 3)) (0.41.2)\r\n",
      "Requirement already satisfied: webencodings in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from bleach!=5.0.0->nbconvert->jupyter->-r requirements.txt (line 10)) (0.5.1)\r\n",
      "Requirement already satisfied: decorator in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 10)) (5.1.1)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 10)) (0.19.1)\r\n",
      "Requirement already satisfied: stack-data in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 10)) (0.6.3)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 10)) (4.9.0)\r\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter->-r requirements.txt (line 10)) (4.2.0)\r\n",
      "Requirement already satisfied: anyio>=3.1.0 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 10)) (4.2.0)\r\n",
      "Requirement already satisfied: argon2-cffi in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 10)) (23.1.0)\r\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 10)) (0.9.0)\r\n",
      "Requirement already satisfied: jupyter-server-terminals in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 10)) (0.5.2)\r\n",
      "Requirement already satisfied: overrides in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 10)) (7.7.0)\r\n",
      "Requirement already satisfied: prometheus-client in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 10)) (0.19.0)\r\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 10)) (1.8.2)\r\n",
      "Requirement already satisfied: terminado>=0.8.3 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 10)) (0.18.0)\r\n",
      "Requirement already satisfied: websocket-client in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 10)) (1.7.0)\r\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from jupyterlab<5,>=4.0.2->notebook->jupyter->-r requirements.txt (line 10)) (2.0.4)\r\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from jupyterlab<5,>=4.0.2->notebook->jupyter->-r requirements.txt (line 10)) (2.2.2)\r\n",
      "Requirement already satisfied: babel>=2.10 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter->-r requirements.txt (line 10)) (2.14.0)\r\n",
      "Requirement already satisfied: json5>=0.9.0 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter->-r requirements.txt (line 10)) (0.9.14)\r\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter->-r requirements.txt (line 10)) (4.21.1)\r\n",
      "Requirement already satisfied: requests>=2.31 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter->-r requirements.txt (line 10)) (2.31.0)\r\n",
      "Requirement already satisfied: fastjsonschema in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from nbformat>=5.7->nbconvert->jupyter->-r requirements.txt (line 10)) (2.19.1)\r\n",
      "Requirement already satisfied: wcwidth in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter->-r requirements.txt (line 10)) (0.2.13)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 3)) (2.27.0)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 3)) (1.2.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 3)) (3.5.2)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 3)) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 3)) (3.0.1)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from beautifulsoup4->nbconvert->jupyter->-r requirements.txt (line 10)) (2.5)\r\n",
      "Requirement already satisfied: idna>=2.8 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 10)) (3.6)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 10)) (1.3.0)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 3)) (5.3.2)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 3)) (0.3.0)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 3)) (4.9)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 3)) (1.3.1)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 10)) (0.8.3)\r\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter->-r requirements.txt (line 10)) (23.2.0)\r\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter->-r requirements.txt (line 10)) (2023.12.1)\r\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter->-r requirements.txt (line 10)) (0.33.0)\r\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter->-r requirements.txt (line 10)) (0.17.1)\r\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 10)) (2.0.7)\r\n",
      "Requirement already satisfied: pyyaml>=5.3 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 10)) (6.0.1)\r\n",
      "Requirement already satisfied: rfc3339-validator in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 10)) (0.1.4)\r\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 10)) (0.1.1)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 10)) (0.7.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook->jupyter->-r requirements.txt (line 10)) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook->jupyter->-r requirements.txt (line 10)) (2.2.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook->jupyter->-r requirements.txt (line 10)) (2023.11.17)\r\n",
      "Requirement already satisfied: argon2-cffi-bindings in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from argon2-cffi->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 10)) (21.2.0)\r\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 10)) (2.0.1)\r\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 10)) (2.4.1)\r\n",
      "Requirement already satisfied: pure-eval in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 10)) (0.2.2)\r\n",
      "Requirement already satisfied: fqdn in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 10)) (1.5.1)\r\n",
      "Requirement already satisfied: isoduration in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 10)) (20.11.0)\r\n",
      "Requirement already satisfied: jsonpointer>1.13 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 10)) (2.4)\r\n",
      "Requirement already satisfied: uri-template in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 10)) (1.3.0)\r\n",
      "Requirement already satisfied: webcolors>=1.11 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 10)) (1.13)\r\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 3)) (0.5.1)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 3)) (3.2.2)\r\n",
      "Requirement already satisfied: cffi>=1.0.1 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 10)) (1.16.0)\r\n",
      "Requirement already satisfied: pycparser in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 10)) (2.21)\r\n",
      "Requirement already satisfied: arrow>=0.15.0 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 10)) (1.3.0)\r\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /Users/nirmolcho/miniconda3/envs/llama2/lib/python3.11/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 10)) (2.8.19.20240106)\r\n",
      "Downloading scikit_learn-1.4.0-1-cp311-cp311-macosx_12_0_arm64.whl (10.6 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m10.6/10.6 MB\u001B[0m \u001B[31m27.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m0:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached seaborn-0.13.2-py3-none-any.whl (294 kB)\r\n",
      "Downloading scipy-1.12.0-cp311-cp311-macosx_12_0_arm64.whl (31.4 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m31.4/31.4 MB\u001B[0m \u001B[31m51.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading opencv_python-4.9.0.80-cp37-abi3-macosx_11_0_arm64.whl (35.4 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m35.4/35.4 MB\u001B[0m \u001B[31m50.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading joblib-1.3.2-py3-none-any.whl (302 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m302.2/302.2 kB\u001B[0m \u001B[31m27.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\r\n",
      "Installing collected packages: threadpoolctl, scipy, opencv-python, joblib, scikit-learn, seaborn\r\n",
      "Successfully installed joblib-1.3.2 opencv-python-4.9.0.80 scikit-learn-1.4.0 scipy-1.12.0 seaborn-0.13.2 threadpoolctl-3.2.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T08:55:21.488044Z",
     "start_time": "2024-02-09T08:55:11.077026Z"
    }
   },
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T08:55:31.411970Z",
     "start_time": "2024-02-09T08:55:25.436928Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models , initializers\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_dir(directory, target_size=(320, 320)):\n",
    "    image_list = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            image_path = os.path.join(directory, filename)\n",
    "            # Load the image using OpenCV\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                print(f\"Warning: Unable to load image '{filename}'\")\n",
    "                continue\n",
    "            \n",
    "            # Convert BGR to RGB format\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Resize the image\n",
    "            resized_image = cv2.resize(image_rgb, target_size)\n",
    "            image_list.append(resized_image)\n",
    "    return image_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"data/monet_jpg/\"\n",
    "monet_image_list = load_images_from_dir(directory_path)\n",
    "print(\"Number of images loaded:\", len(monet_image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"data/photo_jpg/\"\n",
    "image_list = load_images_from_dir(directory_path)\n",
    "print(\"Number of images loaded:\", len(image_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_random_images(image_list):\n",
    "    # Ensure that we have at least 5 images\n",
    "    if len(image_list) < 5:\n",
    "        print(\"Error: Insufficient number of images.\")\n",
    "        return\n",
    "    \n",
    "    # Choose 5 random indices\n",
    "    random_indices = random.sample(range(len(image_list)), 5)\n",
    "    \n",
    "    # Plot the images\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(15, 5))\n",
    "    for i, idx in enumerate(random_indices):\n",
    "        axes[i].imshow(image_list[idx])  # Convert BGR to RGB for Matplotlib\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(f\"Image {idx}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_random_images(image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_random_images(monet_image_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_white_corner(image):\n",
    "    # Convert image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Define the size of the corner region\n",
    "    corner_size = 5\n",
    "    \n",
    "    # Define the four corners\n",
    "    corners = [\n",
    "        gray_image[:corner_size, :corner_size],                # Top-left corner\n",
    "        gray_image[:corner_size, -corner_size:],              # Top-right corner\n",
    "        gray_image[-corner_size:, :corner_size],              # Bottom-left corner\n",
    "        gray_image[-corner_size:, -corner_size:]              # Bottom-right corner\n",
    "    ]\n",
    "    \n",
    "    # Check if all corners are completely white\n",
    "    return all(np.all(corner > 220) for corner in corners)\n",
    "\n",
    "def crop_and_resize(image, target_size=(320, 320)):\n",
    "    # Get the dimensions of the input image\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    # Calculate the center coordinates\n",
    "    center_x = width // 2\n",
    "    center_y = height // 2\n",
    "    \n",
    "    # Calculate the crop boundaries\n",
    "    crop_left = max(0, center_x - 215 // 2)\n",
    "    crop_top = max(0, center_y - 215 // 2)\n",
    "    crop_right = min(width, center_x + 215 // 2)\n",
    "    crop_bottom = min(height, center_y + 215 // 2)\n",
    "    \n",
    "    # Crop the image\n",
    "    cropped_image = image[crop_top:crop_bottom, crop_left:crop_right]\n",
    "    \n",
    "    # Resize the cropped image\n",
    "    resized_image = cv2.resize(cropped_image, target_size)\n",
    "    \n",
    "    return resized_image\n",
    "\n",
    "def show_images_with_white_corner(images):\n",
    "    for idx, image in enumerate(images):\n",
    "        if has_white_corner(image):\n",
    "            cropped_resized_image = crop_and_resize(image)\n",
    "            plt.imshow(image)\n",
    "            plt.title(f\"Image {idx}\")\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "            plt.imshow(cropped_resized_image)\n",
    "            plt.title(f\"Image {idx}\")\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "show_images_with_white_corner(monet_image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_images_with_white_corner(images):\n",
    "    new_images = []\n",
    "    for idx, image in enumerate(images):\n",
    "        if has_white_corner(image):\n",
    "            new_images.append(crop_and_resize(image))\n",
    "        else:\n",
    "            new_images.append(image)\n",
    "\n",
    "    return new_images\n",
    "\n",
    "monet_image_list = change_images_with_white_corner(monet_image_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_resize_quarters(original_image):\n",
    "    # Convert PIL Image to NumPy array\n",
    "    original_image_array = np.array(original_image)\n",
    "    \n",
    "    # Ensure the image is 320x320\n",
    "    if original_image_array.shape[:2] != (320, 320):\n",
    "        print(\"Error: Image size must be 320x320.\")\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    # Split the image into quarters\n",
    "    quarters = []\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            left = j * 160\n",
    "            upper = i * 160\n",
    "            right = left + 160\n",
    "            lower = upper + 160\n",
    "            quarter = original_image_array[upper:lower, left:right, :]\n",
    "            quarters.append(quarter)\n",
    "    \n",
    "    # Resize each quarter to 320x320\n",
    "    resized_quarters = [cv2.resize(quarter, (320, 320)) for quarter in quarters]\n",
    "    \n",
    "    return original_image , resized_quarters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image, quarters = split_and_resize_quarters(monet_image_list[0])\n",
    "if quarters:\n",
    "    # Plot original image\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(original_image)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot each quarter\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "    for i, quarter in enumerate(quarters):\n",
    "        axes[i//2, i%2].imshow(quarter)\n",
    "        axes[i//2, i%2].axis('off')\n",
    "        axes[i//2, i%2].set_title(f\"Quarter {i+1}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_with_high_color_variance(images, threshold):\n",
    "    high_color_var_images = []\n",
    "    \n",
    "    for image in images:\n",
    "        # Convert image to numpy array\n",
    "        image_array = np.array(image)\n",
    "        \n",
    "        # Calculate color variance\n",
    "        color_variance = np.var(image_array)\n",
    "        # Check if color variance is higher than the threshold\n",
    "        if color_variance > threshold:\n",
    "            high_color_var_images.append(image)\n",
    "    \n",
    "    return high_color_var_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_colorful_image = get_images_with_high_color_variance(quarters , 1000)\n",
    "if most_colorful_image:\n",
    "    # Plot each quarter\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "    for i, quarter in enumerate(most_colorful_image):\n",
    "        axes[i//2, i%2].imshow(quarter)\n",
    "        axes[i//2, i%2].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mirror_flip(image):\n",
    "    # Mirror flip the image horizontally\n",
    "    flipped_image = cv2.flip(image, 1)\n",
    "    return flipped_image\n",
    "\n",
    "\n",
    "def aug_pipeline(images, threshold):\n",
    "    augmented_images = []\n",
    "    \n",
    "    for image in images:\n",
    "        # Split into quarters\n",
    "        _ , quarters = split_and_resize_quarters(image)\n",
    "        \n",
    "        # Save only important quarters\n",
    "        important_quarters = get_images_with_high_color_variance(quarters, threshold)\n",
    "\n",
    "        # Mirror flip the original image\n",
    "        mirrored_image = mirror_flip(image)\n",
    "                \n",
    "        # Combine original image, mirrored image, and important quarters\n",
    "        augmented_images.append(image)\n",
    "        augmented_images.append(mirrored_image)\n",
    "        if len(important_quarters) != 0:\n",
    "            augmented_images.extend(important_quarters)\n",
    "    \n",
    "    return augmented_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(monet_image_list))\n",
    "augmented_images = aug_pipeline(monet_image_list, 1000)\n",
    "print(len(augmented_images))\n",
    "plot_random_images(augmented_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save the data in batch for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch size\n",
    "batch_size = 10\n",
    "\n",
    "# Convert lists to TensorFlow datasets\n",
    "monet_dataset = tf.data.Dataset.from_tensor_slices(augmented_images)\n",
    "photo_dataset = tf.data.Dataset.from_tensor_slices(image_list)\n",
    "\n",
    "# Zip the datasets to combine them\n",
    "combined_dataset = tf.data.Dataset.zip((monet_dataset, photo_dataset))\n",
    "\n",
    "# Optionally shuffle and batch the dataset\n",
    "combined_dataset = combined_dataset.shuffle(buffer_size=len(augmented_images)).batch(batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_images_from_batch(dataset, title):\n",
    "    # Get one batch of images from the dataset\n",
    "    images_batch = next(iter(dataset.batch(10)))  # Assuming batch size of 16\n",
    "    # Create a figure with a larger size\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    # Plot each image in the batch\n",
    "    for i, image in enumerate(images_batch):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(image.numpy().astype(\"uint8\"))  # Convert to uint8 for plotting\n",
    "        plt.axis(\"off\")\n",
    "    # Set title and show plot\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "# Plot one batch of Monet images\n",
    "plot_images_from_batch(monet_dataset, \"Monet Images\")\n",
    "\n",
    "# Plot one batch of photo images\n",
    "plot_images_from_batch(photo_dataset, \"Photo Images\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create the objects that neccessary for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def downsample(filters, size, apply_batchnorm=True):\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "  result = tf.keras.Sequential()\n",
    "  result.add(\n",
    "      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                             kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "  if apply_batchnorm:\n",
    "    result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "  result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "  return result\n",
    "\n",
    "\n",
    "sample = next(iter(monet_dataset.batch(1)))  # Assuming batch size of 1\n",
    "sample_float32 = tf.cast(sample, tf.float32)\n",
    "\n",
    "down_model = downsample(3, 4)\n",
    "down_result = down_model(sample_float32)\n",
    "print(down_result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def upsample(filters, size, apply_dropout=False):\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "  result = tf.keras.Sequential()\n",
    "  result.add(\n",
    "    tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
    "                                    padding='same',\n",
    "                                    kernel_initializer=initializer,\n",
    "                                    use_bias=False))\n",
    "\n",
    "  result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "  if apply_dropout:\n",
    "      result.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "  result.add(tf.keras.layers.ReLU())\n",
    "\n",
    "  return result\n",
    "     \n",
    "\n",
    "\n",
    "up_model = upsample(3, 4)\n",
    "up_result = up_model(down_result)\n",
    "print (up_result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define Generator model\n",
    "def Generator():\n",
    "  inputs = tf.keras.layers.Input(shape=[320, 320, 3])\n",
    "  \n",
    "  down_stack = [\n",
    "    downsample(80, 4, apply_batchnorm=False),  # (batch_size, 160, 160, 80)\n",
    "    downsample(160, 4),  # (batch_size, 64, 64, 128)\n",
    "    downsample(320, 4),  # (batch_size, 32, 32, 256)\n",
    "    downsample(640, 4),  # (batch_size, 16, 16, 512)\n",
    "    downsample(640, 4),  # (batch_size, 8, 8, 512)\n",
    "    downsample(640, 4),  # (batch_size, 4, 4, 512)\n",
    "    # downsample(640, 4),  # (batch_size, 2, 2, 512)\n",
    "    # downsample(640, 4),  # (batch_size, 1, 1, 512)\n",
    "  ]\n",
    "\n",
    "  up_stack = [\n",
    "    # upsample(640, 4, apply_dropout=True),  # (batch_size, 2, 2, 1024)\n",
    "    # upsample(640, 4, apply_dropout=True),  # (batch_size, 4, 4, 1024)\n",
    "    upsample(640, 4, apply_dropout=True),  # (batch_size, 8, 8, 1024)\n",
    "    upsample(640, 4 ,apply_dropout=True),  # (batch_size, 16, 16, 1024)\n",
    "    upsample(320, 4),  # (batch_size, 32, 32, 512)\n",
    "    upsample(160, 4),  # (batch_size, 64, 64, 256)\n",
    "    upsample(80, 4),  # (batch_size, 128, 128, 128)\n",
    "  ]\n",
    "\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "  last = tf.keras.layers.Conv2DTranspose(3, 4,\n",
    "                                         strides=2,\n",
    "                                         padding='same',\n",
    "                                         kernel_initializer=initializer,\n",
    "                                         activation='tanh')  # (batch_size, 256, 256, 3)\n",
    "\n",
    "\n",
    "\n",
    "  x = inputs\n",
    "\n",
    "\n",
    "  # Downsampling through the model\n",
    "  skips = []\n",
    "  for down in down_stack:\n",
    "    x = down(x)\n",
    "    skips.append(x)\n",
    "\n",
    "  skips = reversed(skips[:-1])\n",
    "\n",
    "  # Upsampling and establishing the skip connections\n",
    "  for up, skip in zip(up_stack, skips):\n",
    "    x = up(x)\n",
    "    x = tf.keras.layers.Concatenate()([x, skip])\n",
    "\n",
    "  x = last(x)\n",
    "     \n",
    "\n",
    "\n",
    "  return tf.keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "# Test the generator model with random input batch\n",
    "def test_build_generator():\n",
    "\n",
    "\n",
    "    # Build generator model\n",
    "    generator = Generator()\n",
    "    \n",
    "\n",
    "    input_shape = (320, 320, 3)  # Example input shape\n",
    "    # Generate a random batch of input images\n",
    "    batch_size = 4\n",
    "    random_input_batch = tf.random.uniform((batch_size,) + input_shape, minval=0, maxval=1)\n",
    "    \n",
    "    # Forward pass through the generator\n",
    "    generated_images = generator(random_input_batch)\n",
    "    print(generator.summary())\n",
    "\n",
    "    # Check output shape\n",
    "    output_shape = generated_images.shape\n",
    "    expected_output_shape = (batch_size, 320, 320, 3)  # Output shape with batch dimension\n",
    "    \n",
    "    # Check if the output shape matches the expected output shape\n",
    "    assert output_shape == expected_output_shape, \"Output shape mismatch\"\n",
    "    print(\"Test passed!\")\n",
    "\n",
    "# Run the test\n",
    "test_build_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Discriminator model\n",
    "def Discriminator(input_nc = 3, ndf=64, n_layers=3):\n",
    "    inputs = tf.keras.layers.Input(shape=(None, None, input_nc))\n",
    "    x = inputs\n",
    "    nf_mult_prev = 1\n",
    "\n",
    "    # First convolutional layer\n",
    "    x = tf.keras.layers.Conv2D(ndf, kernel_size=4, strides=2, padding='same')(x)\n",
    "    x = tf.keras.layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    nf_mult = 1\n",
    "    # Middle convolutional layers\n",
    "    for n in range(1, n_layers):\n",
    "        nf_mult_prev = nf_mult\n",
    "        nf_mult = min(2 ** n, 8)\n",
    "        x = tf.keras.layers.Conv2D(ndf * nf_mult, kernel_size=4, strides=2, padding='same')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    # Last convolutional layer\n",
    "    nf_mult_prev = nf_mult\n",
    "    nf_mult = min(2 ** n_layers, 8)\n",
    "    x = tf.keras.layers.Conv2D(ndf * nf_mult, kernel_size=4, strides=1, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    # Output convolutional layer\n",
    "    outputs = tf.keras.layers.Conv2D(1, kernel_size=4, strides=1, padding='same')(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Test the discriminator model with random input batch\n",
    "def test_build_discriminator():\n",
    "    # Define input shape\n",
    "    input_shape = (320, 320, 3)  # Example input shape\n",
    "\n",
    "    # Build discriminator model\n",
    "    discriminator = Discriminator(3)\n",
    "    \n",
    "    # Generate a random batch of input images\n",
    "    batch_size = 4\n",
    "    random_input_batch = tf.random.uniform((batch_size,) + input_shape, minval=0, maxval=1)\n",
    "    \n",
    "    # Forward pass through the discriminator\n",
    "    discriminator_output = discriminator(random_input_batch)\n",
    "    \n",
    "    # Check output shape\n",
    "    output_shape = discriminator_output.shape\n",
    "    print(output_shape)\n",
    "    print(discriminator.summary())\n",
    "    expected_output_shape = (batch_size, 40, 40, 1)  # Output shape with batch dimension\n",
    "    \n",
    "    # Check if the output shape matches the expected output shape\n",
    "    assert output_shape == expected_output_shape, \"Output shape mismatch\"\n",
    "    print(\"Test passed!\")\n",
    "\n",
    "# Run the test\n",
    "test_build_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adversarial Loss\n",
    "def adversarial_loss(discriminator, generated):\n",
    "    fake_output = discriminator(generated)\n",
    "    return tf.reduce_mean(tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(fake_output), fake_output))\n",
    "\n",
    "\n",
    "# Cycle Consistency Loss\n",
    "def cycle_consistency_loss(real_images, cycled_images, lambda_weight=10):\n",
    "    real_images = tf.cast(real_images, tf.float32)\n",
    "    cycled_images = tf.cast(cycled_images, tf.float32)\n",
    "    loss = tf.reduce_mean(tf.abs(real_images - cycled_images))\n",
    "    return lambda_weight * loss\n",
    "\n",
    "# Identity Loss\n",
    "def identity_loss(real_images, same_images, lambda_weight=0.5):\n",
    "    real_images = tf.cast(real_images, tf.float32)\n",
    "    same_images = tf.cast(same_images, tf.float32)\n",
    "    loss = tf.reduce_mean(tf.abs(real_images - same_images))\n",
    "    return lambda_weight * 0.5 * loss\n",
    "\n",
    "\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_batch(generator_real2monet, generator_monet2real, discriminator_real, discriminator_monet, batch_real, batch_monet):\n",
    "    with tf.GradientTape() as gen_R2M_tape, tf.GradientTape() as gen_M2R_tape, \\\n",
    "         tf.GradientTape() as disc_r_tape, tf.GradientTape() as disc_m_tape:\n",
    "\n",
    "        # Generate fake images\n",
    "        fake_monet = generator_real2monet(batch_real, training=True)\n",
    "        fake_real = generator_monet2real(batch_monet, training=True)\n",
    "\n",
    "        # Generate reconstructed images\n",
    "        reconstr_real = generator_monet2real(fake_monet, training=True)\n",
    "        reconstr_monet = generator_real2monet(fake_real, training=True)\n",
    "\n",
    "        # Identity mapping loss\n",
    "        identity_loss_real = identity_loss(batch_real, reconstr_real)\n",
    "        identity_loss_monet = identity_loss(batch_monet, reconstr_monet)\n",
    "\n",
    "        # Adversarial loss\n",
    "        adv_loss_R2M = adversarial_loss(discriminator_monet, fake_monet)\n",
    "        adv_loss_M2R = adversarial_loss(discriminator_real, fake_real)\n",
    "\n",
    "\n",
    "        # Cycle consistency loss\n",
    "        cycle_loss = cycle_consistency_loss(batch_real, reconstr_real) + \\\n",
    "                     cycle_consistency_loss(batch_monet, reconstr_monet)\n",
    "\n",
    "        # Total generator loss\n",
    "        total_gen_R2M_loss = adv_loss_R2M + cycle_loss\n",
    "        total_gen_M2R_loss = adv_loss_M2R + cycle_loss\n",
    "\n",
    "    # Compute gradients of generator loss with respect to generator variables\n",
    "    gen_R2M_gradients = gen_R2M_tape.gradient(total_gen_R2M_loss, generator_real2monet.trainable_variables)\n",
    "    gen_M2R_gradients = gen_M2R_tape.gradient(total_gen_M2R_loss, generator_monet2real.trainable_variables)\n",
    "\n",
    "    # Apply gradients to generator variables\n",
    "    generator_real2monet.optimizer.apply_gradients(zip(gen_R2M_gradients, generator_real2monet.trainable_variables))\n",
    "    generator_monet2real.optimizer.apply_gradients(zip(gen_M2R_gradients, generator_monet2real.trainable_variables))\n",
    "\n",
    "    # Train discriminator X\n",
    "    with tf.GradientTape() as disc_r_tape:\n",
    "        disc_real_real_output = discriminator_real(batch_real, training=True)\n",
    "        disc_real_fake_output = discriminator_real(fake_real, training=True)\n",
    "\n",
    "        # Compute discriminator X loss\n",
    "        disc_real_loss = discriminator_loss(disc_real_real_output, disc_real_fake_output)\n",
    "\n",
    "    # Compute gradients of discriminator X loss with respect to discriminator X variables\n",
    "    disc_real_gradients = disc_r_tape.gradient(disc_real_loss, discriminator_real.trainable_variables)\n",
    "\n",
    "    # Apply gradients to discriminator X variables\n",
    "    discriminator_real.optimizer.apply_gradients(zip(disc_real_gradients, discriminator_real.trainable_variables))\n",
    "\n",
    "    # Train discriminator Y\n",
    "    with tf.GradientTape() as disc_m_tape:\n",
    "        disc_monet_real_output = discriminator_monet(batch_monet, training=True)\n",
    "        disc_monet_fake_output = discriminator_monet(fake_monet, training=True)\n",
    "\n",
    "        # Compute discriminator Y loss\n",
    "        disc_monet_loss = discriminator_loss(disc_monet_real_output, disc_monet_fake_output)\n",
    "\n",
    "    # Compute gradients of discriminator Y loss with respect to discriminator Y variables\n",
    "    disc_monet_gradients = disc_m_tape.gradient(disc_monet_loss, discriminator_monet.trainable_variables)\n",
    "\n",
    "    # Apply gradients to discriminator Y variables\n",
    "    discriminator_monet.optimizer.apply_gradients(zip(disc_monet_gradients, discriminator_monet.trainable_variables))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(generator_real2monet, generator_monet2real, discriminator_real, discriminator_monet, combined_dataset, epochs):\n",
    "    num_batches = len(combined_dataset)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        \n",
    "        # Use tqdm to create a progress bar for the batches\n",
    "        progress_bar = tqdm(combined_dataset, total=num_batches, desc=f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        \n",
    "        for batch_real, batch_monet in progress_bar:\n",
    "            train_one_batch(generator_real2monet, generator_monet2real, discriminator_real, discriminator_monet, batch_real, batch_monet)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build and compile the generators\n",
    "generator_real2monet = Generator()\n",
    "generator_monet2real = Generator()\n",
    "generator_real2monet.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5), loss=adversarial_loss)\n",
    "generator_monet2real.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5), loss=adversarial_loss)\n",
    "\n",
    "# Build and compile the discriminators\n",
    "discriminator_real = Discriminator()\n",
    "discriminator_monet = Discriminator()\n",
    "discriminator_real.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5), loss=adversarial_loss)\n",
    "discriminator_monet.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5), loss=adversarial_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(generator_real2monet, generator_monet2real, discriminator_real, discriminator_monet, combined_dataset, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cycle_gan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

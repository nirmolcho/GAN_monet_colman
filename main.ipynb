{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models , initializers\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.optimizers import legacy\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_images_from_dir(directory, target_size=(320, 320)):\n",
    "    image_list = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            image_path = os.path.join(directory, filename)\n",
    "            # Load the image using OpenCV\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                print(f\"Warning: Unable to load image '{filename}'\")\n",
    "                continue\n",
    "            \n",
    "            # Convert BGR to RGB format\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Resize the image\n",
    "            resized_image = cv2.resize(image_rgb, target_size)\n",
    "            image_list.append(resized_image)\n",
    "    return image_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "directory_path = \"data/monet_jpg/\"\n",
    "monet_image_list = load_images_from_dir(directory_path)\n",
    "print(\"Number of images loaded:\", len(monet_image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "directory_path = \"data/photo_jpg/\"\n",
    "image_list = load_images_from_dir(directory_path)\n",
    "print(\"Number of images loaded:\", len(image_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# EDA images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_random_images(image_list):\n",
    "    # Ensure that we have at least 5 images\n",
    "    if len(image_list) < 5:\n",
    "        print(\"Error: Insufficient number of images.\")\n",
    "        return\n",
    "    \n",
    "    # Choose 5 random indices\n",
    "    random_indices = random.sample(range(len(image_list)), 5)\n",
    "    \n",
    "    # Plot the images\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(15, 5))\n",
    "    for i, idx in enumerate(random_indices):\n",
    "        axes[i].imshow(image_list[idx])  # Convert BGR to RGB for Matplotlib\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(f\"Image {idx}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_random_images(image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_random_images(monet_image_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def has_white_corner(image):\n",
    "    # Convert image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Define the size of the corner region\n",
    "    corner_size = 5\n",
    "    \n",
    "    # Define the four corners\n",
    "    corners = [\n",
    "        gray_image[:corner_size, :corner_size],                # Top-left corner\n",
    "        gray_image[:corner_size, -corner_size:],              # Top-right corner\n",
    "        gray_image[-corner_size:, :corner_size],              # Bottom-left corner\n",
    "        gray_image[-corner_size:, -corner_size:]              # Bottom-right corner\n",
    "    ]\n",
    "    \n",
    "    # Check if all corners are completely white\n",
    "    return all(np.all(corner > 220) for corner in corners)\n",
    "\n",
    "def crop_and_resize(image, target_size=(320, 320)):\n",
    "    # Get the dimensions of the input image\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    # Calculate the center coordinates\n",
    "    center_x = width // 2\n",
    "    center_y = height // 2\n",
    "    \n",
    "    # Calculate the crop boundaries\n",
    "    crop_left = max(0, center_x - 215 // 2)\n",
    "    crop_top = max(0, center_y - 215 // 2)\n",
    "    crop_right = min(width, center_x + 215 // 2)\n",
    "    crop_bottom = min(height, center_y + 215 // 2)\n",
    "    \n",
    "    # Crop the image\n",
    "    cropped_image = image[crop_top:crop_bottom, crop_left:crop_right]\n",
    "    \n",
    "    # Resize the cropped image\n",
    "    resized_image = cv2.resize(cropped_image, target_size)\n",
    "    \n",
    "    return resized_image\n",
    "\n",
    "def show_images_with_white_corner(images):\n",
    "    for idx, image in enumerate(images):\n",
    "        if has_white_corner(image):\n",
    "            cropped_resized_image = crop_and_resize(image)\n",
    "            plt.imshow(image)\n",
    "            plt.title(f\"Image {idx}\")\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "            plt.imshow(cropped_resized_image)\n",
    "            plt.title(f\"Image {idx}\")\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "show_images_with_white_corner(monet_image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def change_images_with_white_corner(images):\n",
    "    new_images = []\n",
    "    for idx, image in enumerate(images):\n",
    "        if has_white_corner(image):\n",
    "            new_images.append(crop_and_resize(image))\n",
    "        else:\n",
    "            new_images.append(image)\n",
    "\n",
    "    return new_images\n",
    "\n",
    "monet_image_list = change_images_with_white_corner(monet_image_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def split_and_resize_quarters(original_image):\n",
    "    # Convert PIL Image to NumPy array\n",
    "    original_image_array = np.array(original_image)\n",
    "    \n",
    "    # Ensure the image is 320x320\n",
    "    if original_image_array.shape[:2] != (320, 320):\n",
    "        print(\"Error: Image size must be 320x320.\")\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    # Split the image into quarters\n",
    "    quarters = []\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            left = j * 160\n",
    "            upper = i * 160\n",
    "            right = left + 160\n",
    "            lower = upper + 160\n",
    "            quarter = original_image_array[upper:lower, left:right, :]\n",
    "            quarters.append(quarter)\n",
    "    \n",
    "    # Resize each quarter to 320x320\n",
    "    resized_quarters = [cv2.resize(quarter, (320, 320)) for quarter in quarters]\n",
    "    \n",
    "    return original_image , resized_quarters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "original_image, quarters = split_and_resize_quarters(monet_image_list[2])\n",
    "if quarters:\n",
    "    # Plot original image\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(original_image)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot each quarter\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "    for i, quarter in enumerate(quarters):\n",
    "        axes[i//2, i%2].imshow(quarter)\n",
    "        axes[i//2, i%2].axis('off')\n",
    "        axes[i//2, i%2].set_title(f\"Quarter {i+1}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_images_with_high_color_variance(images, threshold):\n",
    "    high_color_var_images = []\n",
    "    \n",
    "    for image in images:\n",
    "        # Convert image to numpy array\n",
    "        image_array = np.array(image)\n",
    "        \n",
    "        # Calculate color variance\n",
    "        color_variance = np.var(image_array)\n",
    "        # Check if color variance is higher than the threshold\n",
    "        if color_variance > threshold:\n",
    "            high_color_var_images.append(image)\n",
    "    \n",
    "    return high_color_var_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "most_colorful_image = get_images_with_high_color_variance(quarters , 2500)\n",
    "if most_colorful_image:\n",
    "    # Plot each quarter\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "    for i, quarter in enumerate(most_colorful_image):\n",
    "        axes[i//2, i%2].imshow(quarter)\n",
    "        axes[i//2, i%2].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def mirror_flip(image):\n",
    "    # Mirror flip the image horizontally\n",
    "    flipped_image = cv2.flip(image, 1)\n",
    "    return flipped_image\n",
    "\n",
    "\n",
    "def aug_pipeline(images, threshold):\n",
    "    augmented_images = []\n",
    "    \n",
    "    for image in images:\n",
    "        # Split into quarters\n",
    "        _ , quarters = split_and_resize_quarters(image)\n",
    "        \n",
    "        # Save only important quarters\n",
    "        important_quarters = get_images_with_high_color_variance(quarters, threshold)\n",
    "\n",
    "        # Mirror flip the original image\n",
    "        mirrored_image = mirror_flip(image)\n",
    "                \n",
    "        # Combine original image, mirrored image, and important quarters\n",
    "        augmented_images.append(image)\n",
    "        augmented_images.append(mirrored_image)\n",
    "        if len(important_quarters) != 0:\n",
    "            augmented_images.extend(important_quarters)\n",
    "    \n",
    "    return augmented_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(len(monet_image_list))\n",
    "augmented_images = aug_pipeline(monet_image_list, 2500)\n",
    "print(len(augmented_images))\n",
    "plot_random_images(augmented_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# save the data in batch for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for debug\n",
    "# augmented_images = augmented_images[:50]\n",
    "# image_list = image_list[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image(image):\n",
    "    image = (tf.cast(image, tf.float32) / 127.5) - 1\n",
    "    image = tf.reshape(image, [320,320, 3])\n",
    "    return image\n",
    "\n",
    "\n",
    "def encode_image(image):\n",
    "    # Reverse normalization: Convert pixel values from range [-1, 1] to [0, 255]\n",
    "    image = (image + 1) * 127.5\n",
    "    \n",
    "    # Ensure pixel values are within valid range [0, 255]\n",
    "    image = tf.clip_by_value(image, 0, 255)\n",
    "    \n",
    "    # Convert pixel values to uint8 data type\n",
    "    image = tf.cast(image, tf.uint8)\n",
    "    \n",
    "    return image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = random.sample(image_list, len(augmented_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define batch size\n",
    "BATCH_SIZE = 10 # need to select the batch size based on the gpu\n",
    "\n",
    "monet_len, real_len = len(augmented_images), len(image_list)\n",
    "decoded_monet_images = [decode_image(image) for image in augmented_images]\n",
    "decoded_real_images = [decode_image(image) for image in image_list]\n",
    "print(len(decoded_monet_images) ,monet_len )\n",
    "print(len(decoded_real_images) , real_len)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Correct the slicing for augmented_images to split into train, val, and test sets\n",
    "train_monet = decoded_monet_images[:int(0.8 * monet_len)]\n",
    "val_monet = decoded_monet_images[int(0.8 * monet_len):int(0.9 * monet_len)]\n",
    "test_monet = decoded_monet_images[int(0.9 * monet_len):]\n",
    "\n",
    "# Correct the slicing for image_list to split into train, val, and test sets\n",
    "train_real = decoded_real_images[:int(0.8 * real_len)]\n",
    "val_real = decoded_real_images[int(0.8 * real_len):int(0.9 * real_len)]\n",
    "test_real = decoded_real_images[int(0.9 * real_len):]\n",
    "\n",
    "\n",
    "# Convert lists to TensorFlow datasets\n",
    "train_real = tf.data.Dataset.from_tensor_slices(train_real)\n",
    "val_real = tf.data.Dataset.from_tensor_slices(val_real)\n",
    "test_real = tf.data.Dataset.from_tensor_slices(test_real)\n",
    "\n",
    "train_monet = tf.data.Dataset.from_tensor_slices(train_monet)\n",
    "val_monet = tf.data.Dataset.from_tensor_slices(val_monet)\n",
    "test_monet = tf.data.Dataset.from_tensor_slices(test_monet)\n",
    "\n",
    "\n",
    "\n",
    "# Train Dataset\n",
    "train_dataset = tf.data.Dataset.zip((train_real ,train_monet))\n",
    "test_dataset = tf.data.Dataset.zip((test_real ,test_monet))\n",
    "val_dataset = tf.data.Dataset.zip((val_real , val_monet))\n",
    "\n",
    "\n",
    "# Optionally shuffle and batch the dataset\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(train_real)).batch(BATCH_SIZE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "train_monet = train_monet.shuffle(buffer_size=len(train_monet)).batch(BATCH_SIZE)\n",
    "train_real = train_real.shuffle(buffer_size=len(train_real)).batch(BATCH_SIZE)\n",
    "val_monet = val_monet.shuffle(buffer_size=len(val_monet)).batch(BATCH_SIZE)\n",
    "val_real = val_real.shuffle(buffer_size=len(val_real)).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "def plot_images_from_batch(dataset, title, img_to_plot=10):\n",
    "    # Fetch one batch of images\n",
    "    for real_batch ,monet_batch in dataset.take(1):  # Just take one batch from the dataset\n",
    "        plt.figure(figsize=(12, 8))\n",
    "\n",
    "        for i in range(img_to_plot):\n",
    "            # Plot Monet images\n",
    "            plt.subplot(2, img_to_plot, i + 1)\n",
    "            monet_image = encode_image(monet_batch[i])\n",
    "            plt.imshow(monet_image)\n",
    "            plt.title(\"Monet\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            # Plot Real images, adjust subplot index to move to the next row\n",
    "            plt.subplot(2, img_to_plot, i + 1 + img_to_plot)\n",
    "            real_image = encode_image(real_batch[i])\n",
    "            plt.imshow(real_image)\n",
    "            plt.title(\"Real\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "        plt.suptitle(title)\n",
    "        plt.show()\n",
    "\n",
    "# Example usage:\n",
    "plot_images_from_batch(train_dataset, \"Monet and Real Images\", img_to_plot=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# create the objects that neccessary for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def downsample(filters, size, apply_batchnorm=True):\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "  result = tf.keras.Sequential()\n",
    "  result.add(\n",
    "      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                             kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "  if apply_batchnorm:\n",
    "    result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "  result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "  return result\n",
    "\n",
    "\n",
    "sample, _ = next(iter(train_dataset))  # Assuming batch size of 1\n",
    "sample_float32 = tf.cast(sample, tf.float32)\n",
    "\n",
    "down_model = downsample(3, 4)\n",
    "down_result = down_model(sample_float32)\n",
    "print(down_result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def upsample(filters, size, apply_dropout=False):\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "  result = tf.keras.Sequential()\n",
    "  result.add(\n",
    "    tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
    "                                    padding='same',\n",
    "                                    kernel_initializer=initializer,\n",
    "                                    use_bias=False))\n",
    "\n",
    "  result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "  if apply_dropout:\n",
    "      result.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "  result.add(tf.keras.layers.ReLU())\n",
    "\n",
    "  return result\n",
    "     \n",
    "\n",
    "\n",
    "up_model = upsample(3, 4)\n",
    "up_result = up_model(down_result)\n",
    "print (up_result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define Generator model\n",
    "def Generator():\n",
    "  inputs = tf.keras.layers.Input(shape=[320, 320, 3])\n",
    "  \n",
    "  down_stack = [\n",
    "    downsample(80, 4, apply_batchnorm=False),  # (batch_size, 160, 160, 80)\n",
    "    downsample(160, 4),  # (batch_size, 64, 64, 128)\n",
    "    downsample(320, 4),  # (batch_size, 32, 32, 256)\n",
    "    downsample(640, 4),  # (batch_size, 16, 16, 512)\n",
    "    downsample(640, 4),  # (batch_size, 8, 8, 512)\n",
    "    downsample(640, 4),  # (batch_size, 4, 4, 512)\n",
    "    # downsample(640, 4),  # (batch_size, 2, 2, 512)\n",
    "    # downsample(640, 4),  # (batch_size, 1, 1, 512)\n",
    "  ]\n",
    "\n",
    "  up_stack = [\n",
    "    # upsample(640, 4, apply_dropout=True),  # (batch_size, 2, 2, 1024)\n",
    "    # upsample(640, 4, apply_dropout=True),  # (batch_size, 4, 4, 1024)\n",
    "    upsample(640, 4, apply_dropout=True),  # (batch_size, 8, 8, 1024)\n",
    "    upsample(640, 4 ,apply_dropout=True),  # (batch_size, 16, 16, 1024)\n",
    "    upsample(320, 4),  # (batch_size, 32, 32, 512)\n",
    "    upsample(160, 4),  # (batch_size, 64, 64, 256)\n",
    "    upsample(80, 4),  # (batch_size, 128, 128, 128)\n",
    "  ]\n",
    "\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "  last = tf.keras.layers.Conv2DTranspose(3, 4,\n",
    "                                         strides=2,\n",
    "                                         padding='same',\n",
    "                                         kernel_initializer=initializer,\n",
    "                                         activation='tanh')  # (batch_size, 256, 256, 3)\n",
    "\n",
    "\n",
    "\n",
    "  x = inputs\n",
    "\n",
    "\n",
    "  # Downsampling through the model\n",
    "  skips = []\n",
    "  for down in down_stack:\n",
    "    x = down(x)\n",
    "    skips.append(x)\n",
    "\n",
    "  skips = reversed(skips[:-1])\n",
    "\n",
    "  # Upsampling and establishing the skip connections\n",
    "  for up, skip in zip(up_stack, skips):\n",
    "    x = up(x)\n",
    "    x = tf.keras.layers.Concatenate()([x, skip])\n",
    "\n",
    "  x = last(x)\n",
    "     \n",
    "\n",
    "\n",
    "  return tf.keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "# Test the generator model with random input batch\n",
    "def test_build_generator():\n",
    "\n",
    "\n",
    "    # Build generator model\n",
    "    generator = Generator()\n",
    "    \n",
    "\n",
    "    input_shape = (320, 320, 3)  # Example input shape\n",
    "    # Generate a random batch of input images\n",
    "    batch_size = 4\n",
    "    random_input_batch = tf.random.uniform((batch_size,) + input_shape, minval=0, maxval=1)\n",
    "    \n",
    "    # Forward pass through the generator\n",
    "    generated_images = generator(random_input_batch)\n",
    "    print(generator.summary())\n",
    "\n",
    "    # Check output shape\n",
    "    output_shape = generated_images.shape\n",
    "    expected_output_shape = (batch_size, 320, 320, 3)  # Output shape with batch dimension\n",
    "    \n",
    "    # Check if the output shape matches the expected output shape\n",
    "    assert output_shape == expected_output_shape, \"Output shape mismatch\"\n",
    "    print(\"Test passed!\")\n",
    "\n",
    "# Run the test\n",
    "test_build_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define Discriminator model\n",
    "def Discriminator(input_nc=3, ndf=80, n_layers=3):\n",
    "    inputs = tf.keras.layers.Input(shape=(320, 320, input_nc))\n",
    "    x = inputs\n",
    "\n",
    "    # Convolutional blocks\n",
    "    for n in range(n_layers + 1):\n",
    "        nf_mult = min(2**n, 5)\n",
    "        x = tf.keras.layers.Conv2D(ndf * nf_mult, kernel_size=4, strides=2, padding='same')(x)\n",
    "        x = tf.keras.layers.LeakyReLU(0.2)(x)\n",
    "        if n < n_layers:\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    # Output convolutional layer\n",
    "    outputs = tf.keras.layers.Conv2D(1, kernel_size=4, strides=1, padding='same')(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "# Test the discriminator model with random input batch\n",
    "def test_build_discriminator():\n",
    "    # Define input shape\n",
    "    input_shape = (320, 320, 3)  # Example input shape\n",
    "\n",
    "    # Build discriminator model\n",
    "    discriminator = Discriminator(3)\n",
    "    \n",
    "    # Generate a random batch of input images\n",
    "    batch_size = 4\n",
    "    random_input_batch = tf.random.uniform((batch_size,) + input_shape, minval=0, maxval=1)\n",
    "    \n",
    "    # Forward pass through the discriminator\n",
    "    discriminator_output = discriminator(random_input_batch)\n",
    "    \n",
    "    # Check output shape\n",
    "    output_shape = discriminator_output.shape\n",
    "    print(output_shape)\n",
    "    print(discriminator.summary())\n",
    "    expected_output_shape = (batch_size, 20, 20, 1)  # Output shape with batch dimension\n",
    "    \n",
    "    # Check if the output shape matches the expected output shape\n",
    "    assert output_shape == expected_output_shape, \"Output shape mismatch\"\n",
    "    print(\"Test passed!\")\n",
    "\n",
    "# Run the test\n",
    "test_build_discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = legacy.Adam()\n",
    "\n",
    "# Define the loss function (e.g., Mean Squared Error)\n",
    "loss_function = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "# Define a function for training a single model\n",
    "def train_model(model, train_dataset, val_dataset, optimizer, loss_function, num_epochs):\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer, loss=loss_function)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_epoch_loss = 0\n",
    "        val_epoch_loss = 0\n",
    "        \n",
    "        # Training loop\n",
    "        for batch in tqdm(train_dataset, desc=f'Epoch {epoch}'):\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Forward pass\n",
    "                generated_images = model(batch, training=True)\n",
    "                # Compute loss\n",
    "                loss = loss_function(batch, generated_images)\n",
    "            # Compute gradients\n",
    "            gradients = tape.gradient(loss, model.trainable_variables)\n",
    "            # Update weights\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "            # Accumulate training epoch loss\n",
    "            train_epoch_loss += loss\n",
    "            \n",
    "        # Validation loop\n",
    "        for val_batch in tqdm(val_dataset, desc=f'Epoch {epoch}'):\n",
    "            val_generated_images = model(val_batch, training=False)\n",
    "            val_loss = loss_function(val_batch, val_generated_images)\n",
    "            val_epoch_loss += val_loss\n",
    "        \n",
    "        # Average epoch losses\n",
    "        train_epoch_loss /= len(train_dataset)\n",
    "        val_epoch_loss /= len(val_dataset)\n",
    "        \n",
    "        # Append epoch losses\n",
    "        train_losses.append(train_epoch_loss.numpy())\n",
    "        val_losses.append(val_epoch_loss.numpy())\n",
    "        \n",
    "        # Print epoch losses\n",
    "        print(f'Epoch {epoch + 1}, Training Loss: {train_epoch_loss.numpy()}, Validation Loss: {val_epoch_loss.numpy()}')\n",
    "    \n",
    "    # Create a DataFrame of losses\n",
    "    losses_df = pd.DataFrame({'Epoch': range(1, num_epochs + 1), 'Training Loss': train_losses, 'Validation Loss': val_losses})\n",
    "    \n",
    "    return losses_df\n",
    "\n",
    "num_epochs = 20\n",
    "# Train monet_gen\n",
    "print(\"Training monet_gen:\")\n",
    "monet_gen_trained = Generator()\n",
    "monet_losses = train_model(monet_gen_trained, train_monet, val_monet, optimizer, loss_function, num_epochs)\n",
    "\n",
    "# Train real_gen\n",
    "print(\"Training real_gen:\")\n",
    "real_gen_trained = Generator()\n",
    "real_losses = train_model(real_gen_trained, train_real, val_real, optimizer, loss_function, num_epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_gen_trained.save_weights(os.path.join(\"pre_train\", f'generator_m2r.h5'))\n",
    "monet_gen_trained.save_weights(os.path.join(\"pre_train\", f'generator_r2m.h5'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the losses DataFrame to a CSV file\n",
    "monet_losses.to_csv('pre_train/monet_losses.csv', index=False)\n",
    "real_losses.to_csv('pre_train/real_losses.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monet_losses = pd.read_csv('pre_train/monet_losses.csv')\n",
    "real_losses = pd.read_csv('pre_train/real_losses.csv')\n",
    "\n",
    "monet_gen_trained = Generator()\n",
    "real_gen_trained = Generator()\n",
    "\n",
    "real_gen_trained.load_weights(os.path.join(\"pre_train\", f'generator_m2r.h5'))\n",
    "monet_gen_trained.load_weights(os.path.join(\"pre_train\", f'generator_r2m.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(monet_losses['Epoch'], monet_losses['Training Loss'], label='Training Loss')\n",
    "plt.plot(monet_losses['Epoch'], monet_losses['Validation Loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(real_losses['Epoch'], real_losses['Training Loss'], label='Training Loss')\n",
    "plt.plot(real_losses['Epoch'], real_losses['Validation Loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(generator, img):\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "    generated_img = generator.predict(img)[0]\n",
    "    return generated_img\n",
    "\n",
    "for real_batch ,monet_batch in test_dataset.take(1):\n",
    "    real_image = encode_image(real_batch[0])\n",
    "    plt.imshow(real_image)\n",
    "    plt.title(\"Real\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show(block = False)\n",
    "\n",
    "    real_generate = generate_images(real_gen_trained , real_batch[0])\n",
    "    real_generate_img = encode_image(real_generate)\n",
    "    plt.imshow(real_generate_img)\n",
    "    plt.title(\"real_generate\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show(block = False)\n",
    "\n",
    "\n",
    "    print(\"-\"*60)\n",
    "    monet_image = encode_image(monet_batch[0])\n",
    "    plt.imshow(monet_image)\n",
    "    plt.title(\"Monet\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show(block = False)\n",
    "\n",
    "    monet_generate = generate_images(monet_gen_trained , monet_batch[0])\n",
    "    monet_generate_img = encode_image(monet_generate)\n",
    "    plt.imshow(monet_generate_img)\n",
    "    plt.title(\"monet_generate\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show(block = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGan(tf.keras.Model):\n",
    "    def __init__(self, generator_real2monet, generator_monet2real, discriminator_real, discriminator_monet, lr=5e-4, beta_1=0.5):\n",
    "        super(CycleGan, self).__init__()\n",
    "        self.generator_real2monet = generator_real2monet\n",
    "        self.generator_monet2real = generator_monet2real\n",
    "        self.discriminator_real = discriminator_real\n",
    "        self.discriminator_monet = discriminator_monet\n",
    "        self.lr = lr\n",
    "        self.beta_1 = beta_1\n",
    "        \n",
    "    def compile(self, mac=True):\n",
    "        if mac:\n",
    "            optimizer = legacy.Adam(learning_rate=self.lr, beta_1=self.beta_1)\n",
    "        else:\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate=self.lr, beta_1=self.beta_1)\n",
    "            \n",
    "        self.generator_real2monet.compile(optimizer=optimizer)\n",
    "        self.generator_monet2real.compile(optimizer=optimizer)\n",
    "        self.discriminator_real.compile(optimizer=optimizer)\n",
    "        self.discriminator_monet.compile(optimizer=optimizer)\n",
    "        \n",
    "    def adversarial_loss(self, discriminator, generated):\n",
    "        fake_output = discriminator(generated)\n",
    "        return tf.reduce_mean(tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(fake_output), fake_output))\n",
    "    \n",
    "    def cycle_consistency_loss(self, real_images, reconstructed_images):\n",
    "        return tf.reduce_mean(tf.abs(real_images - reconstructed_images))\n",
    "    \n",
    "    def identity_loss(self , real_image, generated_image):\n",
    "        loss = tf.reduce_mean(tf.square(real_image - generated_image))\n",
    "        return loss\n",
    "    \n",
    "    def discriminator_loss(self ,real_output, fake_output):\n",
    "        bce_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "        # Real and fake labels\n",
    "        real_labels = tf.ones_like(real_output)\n",
    "        fake_labels = tf.zeros_like(fake_output)\n",
    "\n",
    "        # Compute losses\n",
    "        real_loss = bce_loss(real_labels, real_output)\n",
    "        fake_loss = bce_loss(fake_labels, fake_output)\n",
    "\n",
    "        # Total loss\n",
    "        total_loss = real_loss + fake_loss\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    \n",
    "    def train_step(self, batch_data):\n",
    "        batch_real, batch_monet = batch_data\n",
    "        \n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            # Generate fake images\n",
    "            fake_monet = self.generator_real2monet(batch_real, training=True)\n",
    "            fake_real = self.generator_monet2real(batch_monet, training=True)\n",
    "\n",
    "            # Generate reconstructed images\n",
    "            reconstr_real = self.generator_monet2real(fake_monet, training=True)\n",
    "            reconstr_monet = self.generator_real2monet(fake_real, training=True)\n",
    "\n",
    "            same_real = self.generator_monet2real(batch_real, training = True)\n",
    "            same_monet = self.generator_real2monet(batch_monet, training = True)\n",
    "\n",
    "            # Adversarial loss\n",
    "            adv_loss_R2M = self.adversarial_loss(self.discriminator_monet, fake_monet)\n",
    "            adv_loss_M2R = self.adversarial_loss(self.discriminator_real, fake_real)\n",
    "\n",
    "            # Cycle consistency loss\n",
    "            cycle_loss = self.cycle_consistency_loss(batch_real, reconstr_real) + \\\n",
    "                         self.cycle_consistency_loss(batch_monet, reconstr_monet)\n",
    "\n",
    "            identity_loss_real = self.identity_loss(batch_real ,same_real )\n",
    "            identity_loss_monet = self.identity_loss(batch_monet ,same_monet )\n",
    "            # Total generator loss\n",
    "            if True:\n",
    "                total_gen_R2M_loss = 2*adv_loss_R2M + cycle_loss  + 2*identity_loss_monet \n",
    "                total_gen_M2R_loss = 2*adv_loss_M2R + cycle_loss + 2*identity_loss_real\n",
    "            else: \n",
    "                total_gen_R2M_loss = 2*adv_loss_R2M + cycle_loss \n",
    "                total_gen_M2R_loss = 2*adv_loss_M2R + cycle_loss \n",
    "\n",
    "            # Compute discriminator losses\n",
    "            disc_real_real_output = self.discriminator_real(batch_real, training=True)\n",
    "            disc_real_fake_output = self.discriminator_real(fake_real, training=True)\n",
    "            disc_monet_real_output = self.discriminator_monet(batch_monet, training=True)\n",
    "            disc_monet_fake_output = self.discriminator_monet(fake_monet, training=True)\n",
    "            disc_real_loss = self.discriminator_loss(disc_real_real_output, disc_real_fake_output)\n",
    "            disc_monet_loss = self.discriminator_loss(disc_monet_real_output, disc_monet_fake_output)\n",
    "            \n",
    "        # Compute gradients of generator loss with respect to generator variables\n",
    "        gen_R2M_gradients = tape.gradient(total_gen_R2M_loss, self.generator_real2monet.trainable_variables)\n",
    "        gen_M2R_gradients = tape.gradient(total_gen_M2R_loss, self.generator_monet2real.trainable_variables)\n",
    "\n",
    "        # Apply gradients to generator variables\n",
    "        self.generator_real2monet.optimizer.apply_gradients(zip(gen_R2M_gradients, self.generator_real2monet.trainable_variables))\n",
    "        self.generator_monet2real.optimizer.apply_gradients(zip(gen_M2R_gradients, self.generator_monet2real.trainable_variables))\n",
    "\n",
    "        # Compute gradients of discriminator losses with respect to discriminator variables\n",
    "        disc_real_gradients = tape.gradient(disc_real_loss, self.discriminator_real.trainable_variables)\n",
    "        disc_monet_gradients = tape.gradient(disc_monet_loss, self.discriminator_monet.trainable_variables)\n",
    "\n",
    "        # Apply gradients to discriminator variables\n",
    "        self.discriminator_real.optimizer.apply_gradients(zip(disc_real_gradients, self.discriminator_real.trainable_variables))\n",
    "        self.discriminator_monet.optimizer.apply_gradients(zip(disc_monet_gradients, self.discriminator_monet.trainable_variables))\n",
    "\n",
    "        return {\n",
    "            \"gen_R2M_loss\": total_gen_R2M_loss,\n",
    "            \"gen_M2R_loss\": total_gen_M2R_loss,\n",
    "            \"disc_real_loss\": disc_real_loss,\n",
    "            \"disc_monet_loss\": disc_monet_loss\n",
    "        }\n",
    "    \n",
    "    def test_step(self, batch_data):\n",
    "        batch_real, batch_monet = batch_data\n",
    "        \n",
    "        # Generate fake images\n",
    "        fake_monet = self.generator_real2monet(batch_real, training=False)\n",
    "        fake_real = self.generator_monet2real(batch_monet, training=False)\n",
    "\n",
    "        # Generate reconstructed images\n",
    "        reconstr_real = self.generator_monet2real(fake_monet, training=False)\n",
    "        reconstr_monet = self.generator_real2monet(fake_real, training=False)\n",
    "          \n",
    "        same_real = self.generator_monet2real(batch_real, training = False)\n",
    "        same_monet = self.generator_real2monet(batch_monet, training = False)\n",
    "        # Adversarial loss\n",
    "        adv_loss_R2M = self.adversarial_loss(self.discriminator_monet, fake_monet)\n",
    "        adv_loss_M2R = self.adversarial_loss(self.discriminator_real, fake_real)\n",
    "\n",
    "        # Cycle consistency loss\n",
    "        cycle_loss = self.cycle_consistency_loss(batch_real, reconstr_real) + \\\n",
    "                    self.cycle_consistency_loss(batch_monet, reconstr_monet)\n",
    "\n",
    "        identity_loss_real = self.identity_loss(batch_real ,same_real )\n",
    "        identity_loss_monet = self.identity_loss(batch_monet ,same_monet )\n",
    "\n",
    "        # Total generator loss\n",
    "        if True:\n",
    "            total_gen_R2M_loss = 2*adv_loss_R2M + cycle_loss  + 2*identity_loss_monet \n",
    "            total_gen_M2R_loss = 2*adv_loss_M2R + cycle_loss + 2*identity_loss_real\n",
    "        else: \n",
    "            total_gen_R2M_loss = 2*adv_loss_R2M + cycle_loss \n",
    "            total_gen_M2R_loss = 2*adv_loss_M2R + cycle_loss \n",
    "\n",
    "        # Compute discriminator losses\n",
    "        disc_real_real_output = self.discriminator_real(batch_real, training=False)\n",
    "        disc_real_fake_output = self.discriminator_real(fake_real, training=False)\n",
    "        disc_monet_real_output = self.discriminator_monet(batch_monet, training=False)\n",
    "        disc_monet_fake_output = self.discriminator_monet(fake_monet, training=False)\n",
    "        disc_real_loss = self.discriminator_loss(disc_real_real_output, disc_real_fake_output)\n",
    "        disc_monet_loss = self.discriminator_loss(disc_monet_real_output, disc_monet_fake_output)\n",
    "\n",
    "        return {\n",
    "            \"gen_R2M_loss\": total_gen_R2M_loss,\n",
    "            \"gen_M2R_loss\": total_gen_M2R_loss,\n",
    "            \"disc_real_loss\": disc_real_loss,\n",
    "            \"disc_monet_loss\": disc_monet_loss\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_real2monet, generator_monet2real = Generator(),Generator()\n",
    "# generator_real2monet.load_weights('pre_train/generator_r2m.h5')\n",
    "# generator_monet2real.load_weights('pre_train/generator_m2r.h5')\n",
    "discriminator_real, discriminator_monet = Discriminator(),Discriminator()\n",
    "lr = 0.0001\n",
    "beta_1 = 0.5\n",
    "\n",
    "models_folder = f\"models/lr_{lr}_beta_{beta_1}\"\n",
    "os.makedirs(models_folder, exist_ok=True)\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "cycle_gan_model = CycleGan(generator_real2monet, generator_monet2real, discriminator_real, discriminator_monet, lr=lr, beta_1=beta_1)\n",
    "\n",
    "# Compile the model\n",
    "cycle_gan_model.compile()\n",
    "\n",
    "num_epochs = 30\n",
    "eval_interval = 2  \n",
    "\n",
    "# Create an empty DataFrame to store training and evaluation metrics\n",
    "log_data = {'Epoch': [], \n",
    "            'Gen R2M Loss Train': [], 'Gen M2R Loss Train': [], \n",
    "            'Disc Real Loss Train': [], 'Disc Monet Loss Train': [],\n",
    "            'Gen R2M Loss Eval': [], 'Gen M2R Loss Eval': [], \n",
    "            'Disc Real Loss Eval': [], 'Disc Monet Loss Eval': []}\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # Initialize tqdm for the training dataset\n",
    "    train_losses = {'Gen R2M Loss': [], 'Gen M2R Loss': [], 'Disc Real Loss': [], 'Disc Monet Loss': []}\n",
    "\n",
    "    for batch_real, batch_monet in tqdm(train_dataset, desc=f'Epoch {epoch}'):\n",
    "        # Perform one training step\n",
    "        train_logs = cycle_gan_model.train_step((batch_real, batch_monet))\n",
    "\n",
    "        # Log training metrics\n",
    "        train_losses['Gen R2M Loss'].append(train_logs['gen_R2M_loss'])\n",
    "        train_losses['Gen M2R Loss'].append(train_logs['gen_M2R_loss'])\n",
    "        train_losses['Disc Real Loss'].append(train_logs['disc_real_loss'])\n",
    "        train_losses['Disc Monet Loss'].append(train_logs['disc_monet_loss'])\n",
    "\n",
    "    # Calculate average training metrics\n",
    "    avg_train_losses = {k + ' Train': np.mean(v) for k, v in train_losses.items()}\n",
    "    \n",
    "    cycle_gan_model.generator_real2monet.save_weights(os.path.join(models_folder, f'generator_real2monet_epoch_{epoch}.h5'))\n",
    "    cycle_gan_model.generator_monet2real.save_weights(os.path.join(models_folder, f'generator_monet2real_epoch_{epoch}.h5'))\n",
    "    cycle_gan_model.discriminator_real.save_weights(os.path.join(models_folder, f'discriminator_real_epoch_{epoch}.h5'))\n",
    "    cycle_gan_model.discriminator_monet.save_weights(os.path.join(models_folder, f'discriminator_monet_epoch_{epoch}.h5'))\n",
    "    \n",
    "    # Evaluate the model every eval_interval epochs\n",
    "    if epoch % eval_interval == 0:\n",
    "        eval_metrics = {'Gen R2M Loss': 0.0, 'Gen M2R Loss': 0.0, 'Disc Real Loss': 0.0, 'Disc Monet Loss': 0.0}  # Initialize evaluation metrics\n",
    "        num_batches = 0\n",
    "\n",
    "        # Initialize tqdm for the evaluation dataset\n",
    "        for batch_real_eval, batch_monet_eval in tqdm(val_dataset, desc=f'Eval at Epoch {epoch}'):\n",
    "            # Perform one evaluation step\n",
    "            eval_logs = cycle_gan_model.test_step((batch_real_eval, batch_monet_eval))\n",
    "\n",
    "            # Accumulate evaluation metrics\n",
    "            eval_metrics['Gen R2M Loss'] += eval_logs['gen_R2M_loss']\n",
    "            eval_metrics['Gen M2R Loss'] += eval_logs['gen_M2R_loss']\n",
    "            eval_metrics['Disc Real Loss'] += eval_logs['disc_real_loss']\n",
    "            eval_metrics['Disc Monet Loss'] += eval_logs['disc_monet_loss']\n",
    "            num_batches += 1\n",
    "\n",
    "        # Calculate average evaluation metrics\n",
    "        for metric in eval_metrics:\n",
    "            eval_metrics[metric] /= num_batches\n",
    "\n",
    "        # Log evaluation metrics\n",
    "        avg_eval_metrics = {k + ' Eval': float(v) for k, v in eval_metrics.items()}\n",
    "\n",
    "        # Append metrics to log_data\n",
    "        log_data['Epoch'].append(epoch)\n",
    "        for key, value in avg_train_losses.items():\n",
    "            if key in log_data:\n",
    "                log_data[key].append(value)\n",
    "            else:\n",
    "                log_data[key] = [value]\n",
    "\n",
    "        for key, value in avg_eval_metrics.items():\n",
    "            if key in log_data:\n",
    "                log_data[key].append(value)\n",
    "            else:\n",
    "                log_data[key] = [value]\n",
    "\n",
    "        print(log_data)\n",
    "\n",
    "# Convert log_data to a pandas DataFrame\n",
    "log_df = pd.DataFrame(log_data)\n",
    "\n",
    "# Save log_df to CSV file\n",
    "log_df.to_csv(f'results/log_lr_{lr}_beta_{beta_1}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(df_losses):\n",
    "    epochs = df_losses['Epoch']\n",
    "    gen_R2M_loss_train = df_losses['Gen R2M Loss Train']\n",
    "    gen_M2R_loss_train = df_losses['Gen M2R Loss Train']\n",
    "    disc_real_loss_train = df_losses['Disc Real Loss Train']\n",
    "    disc_monet_loss_train = df_losses['Disc Monet Loss Train']\n",
    "    gen_R2M_loss_eval = df_losses['Gen R2M Loss Eval']\n",
    "    gen_M2R_loss_eval = df_losses['Gen M2R Loss Eval']\n",
    "    disc_real_loss_eval = df_losses['Disc Real Loss Eval']\n",
    "    disc_monet_loss_eval = df_losses['Disc Monet Loss Eval']\n",
    "\n",
    "    # Plot the data\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Plot training loss\n",
    "    plt.plot(epochs, gen_R2M_loss_train, label='Gen R2M Loss Train', marker='o')\n",
    "    plt.plot(epochs, gen_M2R_loss_train, label='Gen M2R Loss Train', marker='o')\n",
    "    plt.plot(epochs, disc_real_loss_train, label='Disc Real Loss Train', marker='o')\n",
    "    plt.plot(epochs, disc_monet_loss_train, label='Disc Monet Loss Train', marker='o')\n",
    "\n",
    "    # Plot evaluation loss\n",
    "    plt.plot(epochs, gen_R2M_loss_eval, label='Gen R2M Loss Eval', marker='o')\n",
    "    plt.plot(epochs, gen_M2R_loss_eval, label='Gen M2R Loss Eval', marker='o')\n",
    "    plt.plot(epochs, disc_real_loss_eval, label='Disc Real Loss Eval', marker='o')\n",
    "    plt.plot(epochs, disc_monet_loss_eval, label='Disc Monet Loss Eval', marker='o')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss Over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(generator, img):\n",
    "    img = np.expand_dims(img, axis=0)  \n",
    "    generated_img = generator.predict(img)[0]\n",
    "    return generated_img\n",
    "\n",
    "\n",
    "def plot_predictions(test_dataset , generator_monet2real , generator_real2monet):\n",
    "    for real_batch ,monet_batch in test_dataset.take(1):\n",
    "        real_image = encode_image(real_batch[0])\n",
    "        plt.imshow(real_image)\n",
    "        plt.title(\"Real\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show(block = False)\n",
    "\n",
    "        monet_generate = generate_images(generator_real2monet , real_batch[0])\n",
    "        monet_generate_img = encode_image(monet_generate)\n",
    "        plt.imshow(monet_generate_img)\n",
    "        plt.title(\"monet_generate\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show(block = False)\n",
    "\n",
    "        real_generate = generate_images(generator_monet2real ,monet_generate)\n",
    "        real_generate_img = encode_image(real_generate)\n",
    "        plt.imshow(real_generate_img)\n",
    "        plt.title(\"real_generate\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show(block = False)\n",
    "\n",
    "        print(\"-\"*60)\n",
    "        monet_image = encode_image(monet_batch[0])\n",
    "        plt.imshow(monet_image)\n",
    "        plt.title(\"Monet\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show(block = False)\n",
    "\n",
    "        real_generate = generate_images(generator_monet2real , monet_batch[0])\n",
    "        real_generate_img = encode_image(real_generate)\n",
    "        plt.imshow(real_generate_img)\n",
    "        plt.title(\"realt_generate\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show(block = False)\n",
    "\n",
    "        monet_generate = generate_images(generator_real2monet ,real_generate)\n",
    "        monet_generate_img = encode_image(monet_generate)\n",
    "        plt.imshow(monet_generate_img)\n",
    "        plt.title(\"monet_generate\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show(block = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_losses_identity = pd.read_csv('results/log_lr_0.0001_beta_0.5_identity.csv')\n",
    "print(df_losses_identity.head())\n",
    "\n",
    "df_losses_pretrain_identity = pd.read_csv('results/log_lr_0.0001_beta_0.5_pretrain_identity.csv')\n",
    "print(df_losses_pretrain_identity.head())\n",
    "\n",
    "df_losses_pretrain = pd.read_csv('results/log_lr_0.0001_beta_0.5_pretrain.csv')\n",
    "print(df_losses_pretrain.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(df_losses_identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(df_losses_pretrain_identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(df_losses_pretrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = 30\n",
    "models_folder = \"models/lr_0.0001_beta_0.5_identity\"\n",
    "generator_real2monet, generator_monet2real = Generator(),Generator()\n",
    "generator_real2monet.load_weights(os.path.join(models_folder, f'generator_real2monet_epoch_{best_epoch}.h5'))\n",
    "generator_monet2real.load_weights(os.path.join(models_folder, f'generator_monet2real_epoch_{best_epoch}.h5'))\n",
    "\n",
    "print(\"identity batch 30\")\n",
    "plot_predictions(test_dataset , generator_monet2real , generator_real2monet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = 20\n",
    "models_folder = \"models/lr_0.0001_beta_0.5_pretrain\"\n",
    "generator_real2monet, generator_monet2real = Generator(),Generator()\n",
    "generator_real2monet.load_weights(os.path.join(models_folder, f'generator_real2monet_epoch_{best_epoch}.h5'))\n",
    "generator_monet2real.load_weights(os.path.join(models_folder, f'generator_monet2real_epoch_{best_epoch}.h5'))\n",
    "\n",
    "print(\"pretrain batch 20\")\n",
    "plot_predictions(test_dataset , generator_monet2real , generator_real2monet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = 20\n",
    "models_folder = \"models/lr_0.0001_beta_0.5_pretrain_identity\"\n",
    "generator_real2monet, generator_monet2real = Generator(),Generator()\n",
    "generator_real2monet.load_weights(os.path.join(models_folder, f'generator_real2monet_epoch_{best_epoch}.h5'))\n",
    "generator_monet2real.load_weights(os.path.join(models_folder, f'generator_monet2real_epoch_{best_epoch}.h5'))\n",
    "\n",
    "print(\"pretrain_identity batch 20\")\n",
    "plot_predictions(test_dataset , generator_monet2real , generator_real2monet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evel best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to change all this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = 30\n",
    "models_folder = \"models/lr_0.0001_beta_0.5_identity\"\n",
    "generator_real2monet, generator_monet2real = Generator(),Generator()\n",
    "generator_real2monet.load_weights(os.path.join(models_folder, f'generator_real2monet_epoch_{best_epoch}.h5'))\n",
    "generator_monet2real.load_weights(os.path.join(models_folder, f'generator_monet2real_epoch_{best_epoch}.h5'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Function to calculate FID\n",
    "def calculate_fid(mu_real, sigma_real, mu_gen, sigma_gen):\n",
    "    fid = np.sum((mu_real - mu_gen)**2) + np.trace(sigma_real + sigma_gen - 2 * np.sqrt(np.dot(sigma_real, sigma_gen)))\n",
    "    return fid\n",
    "\n",
    "# Function to calculate memorization distance\n",
    "def calculate_memorization_distance(real_samples, generated_samples):\n",
    "    distances = []\n",
    "    for gen_sample in generated_samples:\n",
    "        min_distance = np.inf\n",
    "        for real_sample in real_samples:\n",
    "            distance = cosine(gen_sample, real_sample)\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "        distances.append(min_distance)\n",
    "    return np.mean(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load a pre-trained Inception model for feature extraction\n",
    "inception_model = tf.keras.applications.InceptionV3(include_top=False, pooling='avg')\n",
    "\n",
    "real_images_features_all = []\n",
    "monet_images_features_all = []\n",
    "\n",
    "generated_monet_features_all = []\n",
    "generated_real_features_all = []\n",
    "\n",
    "# Loop over the dataset\n",
    "for real_batch, monet_batch in test_dataset:\n",
    "    real_images_features = inception_model.predict(encode_image(real_batch))\n",
    "    monet_images_features = inception_model.predict(encode_image(monet_batch))\n",
    "\n",
    "    generated_monet_features = inception_model.predict(generator_real2monet(encode_image(real_batch) , training = False))\n",
    "    generated_real_features = inception_model.predict(generator_monet2real(encode_image(monet_batch) , training = False))\n",
    "\n",
    "    # Accumulate features for the entire dataset\n",
    "    real_images_features_all.append(real_images_features)\n",
    "    monet_images_features_all.append(monet_images_features)\n",
    "    generated_monet_features_all.append(generated_monet_features)\n",
    "    generated_real_features_all.append(generated_real_features)\n",
    "\n",
    "# Concatenate features from all batches\n",
    "real_images_features_all = np.concatenate(real_images_features_all)\n",
    "monet_images_features_all = np.concatenate(monet_images_features_all)\n",
    "generated_monet_features_all = np.concatenate(generated_monet_features_all)\n",
    "generated_real_features_all = np.concatenate(generated_real_features_all)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean and covariance of features for real images\n",
    "mu_real = np.mean(real_images_features_all, axis=0)\n",
    "sigma_real = np.cov(real_images_features_all, rowvar=False)\n",
    "\n",
    "# Calculate mean and covariance of features for monet images\n",
    "mu_monet = np.mean(monet_images_features_all, axis=0)\n",
    "sigma_monet = np.cov(monet_images_features_all, rowvar=False)\n",
    "\n",
    "# Calculate mean and covariance of features for generated Monet images\n",
    "mu_gen_monet = np.mean(generated_monet_features_all, axis=0)\n",
    "sigma_gen_monet = np.cov(generated_monet_features_all, rowvar=False)\n",
    "\n",
    "# Calculate mean and covariance of features for generated real images\n",
    "mu_gen_real = np.mean(generated_real_features_all, axis=0)\n",
    "sigma_gen_real = np.cov(generated_real_features_all, rowvar=False)\n",
    "\n",
    "# Compute FID scores\n",
    "fid_score_monet = calculate_fid(mu_monet, sigma_monet, mu_gen_monet, sigma_gen_monet)\n",
    "fid_score_real = calculate_fid(mu_real, sigma_real, mu_gen_real, sigma_gen_real)\n",
    "\n",
    "# Compute memorization distance for generated Monet images\n",
    "memorization_distance_monet = calculate_memorization_distance(real_images_features_all, generated_monet_features_all)\n",
    "\n",
    "# Compute memorization distance for generated real images\n",
    "memorization_distance_real = calculate_memorization_distance(real_images_features_all, generated_real_features_all)\n",
    "\n",
    "# Threshold memorization distances based on epsilon\n",
    "epsilon = 0.1\n",
    "if memorization_distance_monet > epsilon:\n",
    "    memorization_distance_monet = 1.0\n",
    "\n",
    "if memorization_distance_real > epsilon:\n",
    "    memorization_distance_real = 1.0\n",
    "\n",
    "# Calculate MiFID scores\n",
    "mifid_score_monet = fid_score_monet * memorization_distance_monet\n",
    "mifid_score_real = fid_score_real * memorization_distance_real\n",
    "\n",
    "print(\"FID Score (Monet):\", fid_score_monet)\n",
    "print(\"Memorization Distance (Monet):\", memorization_distance_monet)\n",
    "print(\"MiFID Score (Monet):\", mifid_score_monet)\n",
    "\n",
    "print(\"FID Score (Real):\", fid_score_real)\n",
    "print(\"Memorization Distance (Real):\", memorization_distance_real)\n",
    "print(\"MiFID Score (Real):\", mifid_score_real)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"sefe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save results for kaggle \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ../images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"data/photo_jpg/\"\n",
    "image_list = load_images_from_dir(directory_path)\n",
    "print(\"Number of images loaded:\", len(image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = 30\n",
    "models_folder = \"models/lr_0.0001_beta_0.5_identity\"\n",
    "generator_real2monet = Generator()\n",
    "generator_real2monet.load_weights(os.path.join(models_folder, f'generator_real2monet_epoch_{best_epoch}.h5'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "for image in image_list:\n",
    "    real_image = decode_image(image)\n",
    "    \n",
    "    monet_generate = generate_images(generator_real2monet , real_image)\n",
    "    monet_generate_img = encode_image(monet_generate).numpy()\n",
    "    monet_generate_img_fixed_size = cv2.resize(monet_generate_img, (256, 256))\n",
    "    # print(monet_generate_img_fixed_size.shape)\n",
    "    # plt.imshow(monet_generate_img_fixed_size)\n",
    "    # plt.title(\"Real\")\n",
    "    # plt.axis(\"off\")\n",
    "    # plt.show(block = False)\n",
    "  \n",
    "    cv2.imwrite(f\"../images/{i}.jpg\", monet_generate_img_fixed_size)\n",
    "    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_folder_path = '../images'  \n",
    "zip_filename = 'images.zip'\n",
    "shutil.make_archive(zip_filename.split('.')[0], 'zip', images_folder_path)\n",
    "print(f\"Images folder has been successfully zipped to {zip_filename}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cycle_gan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
